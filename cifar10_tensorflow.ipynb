{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjX8usDIcWGXYgWgGZC/Ks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitsharmas97/Emotion_detection/blob/main/cifar10_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "wiuamGneITdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "w0fRcy_GHiQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn=Sequential()"
      ],
      "metadata": {
        "id": "tv9qoIMiIKIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn.add(Flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJq6Tqp4H4XT",
        "outputId": "768b5b2f-131d-487f-c47a-3e24a1653582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(Dense(128,activation='relu'))\n",
        "cnn.add(Dense(64,activation='relu'))\n",
        "cnn.add(Dense(32,activation='relu'))\n",
        "cnn.add(Dense(16,activation='relu'))\n",
        "cnn.add(Dense(8,activation='relu'))\n",
        "cnn.add(Dense(4,activation='relu'))\n",
        "cnn.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "4fYvQYGqJyn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c810b17"
      },
      "source": [
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ayush1220/cifar10\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kDztDbqMH1q",
        "outputId": "aaea59d1-05d7-4f4d-eb50-75ea4aaee056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ayush1220/cifar10/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CeeaD9YCMJ7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuB-8cpbMYvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "T3vCJ43sNBd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walkthrough_path = \"/kaggle/input/cifar10\"\n",
        "walk_through(walkthrough_path)"
      ],
      "metadata": {
        "id": "gA3JnAIjNEcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=os.path.join(path, 'cifar10', 'train')\n",
        "test=os.path.join(path, 'cifar10', 'test')\n",
        "dataset_path=path"
      ],
      "metadata": {
        "id": "1wX8fQX5N4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8pvxooIN_zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = os.path.join(dataset_path)\n",
        "train_img_dir = os.path.join(base_dir, 'train')\n",
        "test_img_dir = os.path.join(base_dir, 'test')"
      ],
      "metadata": {
        "id": "0W-o0Dt3NIrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zp8HXlr1OG6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train,\n",
        "                                                 target_size=(64, 64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test,\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAdtwSMPPXl",
        "outputId": "852b737c-d459-49c6-a104-3cc7c5801451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(x=training_set, validation_data=test_set, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoCg5dkAPUzM",
        "outputId": "17fa7828-8c29-4c1f-ad51-913fdb7cb0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 55ms/step - accuracy: 0.1766 - loss: 2.1773 - val_accuracy: 0.3171 - val_loss: 1.8765\n",
            "Epoch 2/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.3734 - loss: 1.7025 - val_accuracy: 0.4167 - val_loss: 1.6152\n",
            "Epoch 3/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.4581 - loss: 1.4669 - val_accuracy: 0.5384 - val_loss: 1.3331\n",
            "Epoch 4/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.5353 - loss: 1.3235 - val_accuracy: 0.5809 - val_loss: 1.2462\n",
            "Epoch 5/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.5888 - loss: 1.2004 - val_accuracy: 0.6090 - val_loss: 1.1440\n",
            "Epoch 6/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.6228 - loss: 1.1234 - val_accuracy: 0.6477 - val_loss: 1.1855\n",
            "Epoch 7/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.6400 - loss: 1.0678 - val_accuracy: 0.6600 - val_loss: 1.0419\n",
            "Epoch 8/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.6623 - loss: 1.0132 - val_accuracy: 0.6931 - val_loss: 0.9504\n",
            "Epoch 9/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.6916 - loss: 0.9276 - val_accuracy: 0.7144 - val_loss: 0.8886\n",
            "Epoch 10/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.7110 - loss: 0.8801 - val_accuracy: 0.6695 - val_loss: 1.0119\n",
            "Epoch 11/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7249 - loss: 0.8312 - val_accuracy: 0.7468 - val_loss: 0.7977\n",
            "Epoch 12/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7309 - loss: 0.8087 - val_accuracy: 0.7152 - val_loss: 0.8807\n",
            "Epoch 13/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7403 - loss: 0.7820 - val_accuracy: 0.7519 - val_loss: 0.7802\n",
            "Epoch 14/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7460 - loss: 0.7512 - val_accuracy: 0.7598 - val_loss: 0.7403\n",
            "Epoch 15/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7582 - loss: 0.7214 - val_accuracy: 0.6525 - val_loss: 1.0427\n",
            "Epoch 16/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7660 - loss: 0.6991 - val_accuracy: 0.7796 - val_loss: 0.6938\n",
            "Epoch 17/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7705 - loss: 0.6810 - val_accuracy: 0.7545 - val_loss: 0.7957\n",
            "Epoch 18/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7783 - loss: 0.6714 - val_accuracy: 0.7587 - val_loss: 0.7393\n",
            "Epoch 19/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 51ms/step - accuracy: 0.7784 - loss: 0.6625 - val_accuracy: 0.7339 - val_loss: 0.8329\n",
            "Epoch 20/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7866 - loss: 0.6457 - val_accuracy: 0.7466 - val_loss: 0.7770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(x=training_set, validation_data=test_set, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLgTD2dP3lHM",
        "outputId": "57655e9a-1788-47ce-9465-b879bc13f7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.7918 - loss: 0.6301 - val_accuracy: 0.7737 - val_loss: 0.7326\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 52ms/step - accuracy: 0.7915 - loss: 0.6185 - val_accuracy: 0.7825 - val_loss: 0.7039\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.8018 - loss: 0.6033 - val_accuracy: 0.7786 - val_loss: 0.6981\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.8008 - loss: 0.5946 - val_accuracy: 0.7879 - val_loss: 0.6850\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.8095 - loss: 0.5779 - val_accuracy: 0.7901 - val_loss: 0.6943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(x=training_set, validation_data=test_set, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klEUAZL65NMM",
        "outputId": "8e6de1f4-3dc3-4d0d-9493-62398cf62538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.8158 - loss: 0.5632 - val_accuracy: 0.7951 - val_loss: 0.6512\n",
            "Epoch 2/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.8170 - loss: 0.5574 - val_accuracy: 0.8084 - val_loss: 0.6229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(x=training_set, validation_data=test_set, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8IOkQwm55nM",
        "outputId": "4a03804f-4d7b-44db-ec65-f440cc1273f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.8184 - loss: 0.5537 - val_accuracy: 0.7953 - val_loss: 0.6560\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.8165 - loss: 0.5482 - val_accuracy: 0.8022 - val_loss: 0.6181\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.8198 - loss: 0.5428 - val_accuracy: 0.8049 - val_loss: 0.6582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7zYos7p63jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a476b6b2",
        "outputId": "6a7fed48-9d91-451f-9b87-6d82ceca5e14"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import random\n",
        "\n",
        "# Get the class labels from the training set\n",
        "class_labels = list(training_set.class_indices.keys())\n",
        "\n",
        "# Get a list of all image files in the test directory\n",
        "test_image_files = []\n",
        "for root, _, files in os.walk(test):\n",
        "    for file in files:\n",
        "        if file.endswith(('jpg', 'jpeg', 'png')):\n",
        "            test_image_files.append(os.path.join(root, file))\n",
        "\n",
        "# Select 10 random image files\n",
        "random_image_paths = random.sample(test_image_files, 10)\n",
        "\n",
        "# Load, preprocess, and predict for each image\n",
        "print(\"Predictions for 10 random images from the test set:\")\n",
        "for img_path in random_image_paths:\n",
        "    # Load the image\n",
        "    img = image.load_img(img_path, target_size=(64, 64))\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale the image like the training data\n",
        "\n",
        "    # Predict the class\n",
        "    predictions = cnn.predict(img_array)\n",
        "\n",
        "    # Get the predicted class label\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    # Extract the original image filename and its true class from the path\n",
        "    # Assuming the directory structure is test/class_name/image_name.jpg\n",
        "    true_class_label = os.path.basename(os.path.dirname(img_path))\n",
        "\n",
        "\n",
        "    print(f\"Image: {os.path.basename(img_path)}, Predicted: {predicted_class_label}, True: {true_class_label}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for 10 random images from the test set:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Image: 0080.png, Predicted: dog, True: dog\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Image: 0277.png, Predicted: frog, True: bird\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Image: 0523.png, Predicted: automobile, True: automobile\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Image: 0411.png, Predicted: ship, True: ship\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Image: 0377.png, Predicted: automobile, True: automobile\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Image: 0971.png, Predicted: deer, True: deer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Image: 0191.png, Predicted: truck, True: airplane\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Image: 0664.png, Predicted: dog, True: dog\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Image: 0308.png, Predicted: truck, True: truck\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Image: 0193.png, Predicted: automobile, True: automobile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7d31987",
        "outputId": "eba7f020-90aa-48a0-908b-d621d1590b2b"
      },
      "source": [
        "loss, accuracy = cnn.evaluate(test_set)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8110 - loss: 0.6458\n",
            "Test Loss: 0.6582\n",
            "Test Accuracy: 0.8049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "636aa023"
      },
      "source": [
        "cnn.save('cifar10_cnn_model.keras')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}